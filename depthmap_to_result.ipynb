{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from datasets.data_io import *\n",
    "import scipy\n",
    "import torch \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "list_obj = [\"bear\", \"buddha\", \"cow\", \"pot2\", \"reading\"]\n",
    "\n",
    "\n",
    "def read_img(filename):\n",
    "        img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "        img = (img.astype(np.float32) - np.min(img)) / (np.max(img) - np.min(img))  #scale\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toImage(tensor, saving_directory, min_1 = 1450, max_1 = 1600):\n",
    "    plt.imshow(tensor, vmin = min_1, vmax = max_1)\n",
    "    plt.colorbar()\n",
    "    plt.savefig(saving_directory)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for obj_index in range(5):\n",
    "    for view_index in range(20):\n",
    "        sum_of_depthmap = 0\n",
    "        for lighting_index in range(96):\n",
    "            filename = list_obj[obj_index] + f\"_view{view_index+1}\" + f\"_lighting{lighting_index}\" + \".pt\"\n",
    "            depthmap = torch.load(f\"/playpen-nas-ssd/xiaolong/project/MVSNet_pytorch/result/{filename}\")\n",
    "            sum_of_depthmap += depthmap[\"depth\"]\n",
    "        sum_of_depthmap /= 96\n",
    "        saving_directory_img = \"/playpen-nas-ssd/xiaolong/project/MVSNet_pytorch/result_combined_lighting/\" + list_obj[obj_index] + f\"_view{view_index+1}\" + \".png\"\n",
    "        saving_directory_tensor = \"/playpen-nas-ssd/xiaolong/project/MVSNet_pytorch/result_combined_lighting/\" + list_obj[obj_index] + f\"_view{view_index+1}\" + \".pt\"\n",
    "        toImage(sum_of_depthmap, saving_directory_img, min_1 = 1450, max_1 = 1600)\n",
    "        torch.save(sum_of_depthmap, saving_directory_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/playpen-nas-ssd/xiaolong/project/MVSNet_pytorch/result_combined_lighting_notupscaled/bear_view1.png'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saving_directory_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lighting78', 'png']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"reading_view20_lighting78.png\"\n",
    "b = a.split(\"_\")\n",
    "b[-1].split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(mat,ksize = (4,4),method='max',pad=False):\n",
    "    '''Non-overlapping pooling on 2D or 3D data.\n",
    "\n",
    "    <mat>: ndarray, input array to pool.\n",
    "    <ksize>: tuple of 2, kernel size in (ky, kx).\n",
    "    <method>: str, 'max for max-pooling, \n",
    "                   'mean' for mean-pooling.\n",
    "    <pad>: bool, pad <mat> or not. If no pad, output has size\n",
    "           n//f, n being <mat> size, f being kernel size.\n",
    "           if pad, output has size ceil(n/f).\n",
    "\n",
    "    Return <result>: pooled matrix.\n",
    "    '''\n",
    "    m, n = mat.shape[:2]\n",
    "    ky,kx=ksize\n",
    "\n",
    "    _ceil=lambda x,y: int(np.ceil(x/float(y)))\n",
    "\n",
    "    if pad:\n",
    "        ny=_ceil(m,ky)\n",
    "        nx=_ceil(n,kx)\n",
    "        size=(ny*ky, nx*kx)+mat.shape[2:]\n",
    "        mat_pad=np.full(size,np.nan)\n",
    "        mat_pad[:m,:n,...]=mat\n",
    "    else:\n",
    "        ny=m//ky\n",
    "        nx=n//kx\n",
    "        mat_pad=mat[:ny*ky, :nx*kx, ...]\n",
    "\n",
    "    new_shape=(ny,ky,nx,kx)+mat.shape[2:]\n",
    "\n",
    "    if method=='max':\n",
    "        result=np.nanmax(mat_pad.reshape(new_shape),axis=(1,3))\n",
    "    else:\n",
    "        result=np.nanmean(mat_pad.reshape(new_shape),axis=(1,3))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_260272/3603461707.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gt = torch.tensor(gt)\n"
     ]
    }
   ],
   "source": [
    "obj_error = torch.ones((5,20))\n",
    "for obj_index in range(5):\n",
    "    for view_index in range(1, 21):\n",
    "        if  view_index  < 10:\n",
    "                gt_view = f\"view_0{view_index}\"\n",
    "        else:\n",
    "                gt_view = f\"view_{view_index}\"\n",
    "        gt = np.load(f\"/playpen-nas-ssd/xiaolong/data/DiLiGenT-MV/mvpmsData/{list_obj[obj_index]}PNG/depth/{gt_view}.npy\")\n",
    "        prediction = torch.load(f\"/playpen-nas-ssd/xiaolong/project/MVSNet_pytorch/result_combined_lighting/{list_obj[obj_index]}_view{view_index}.pt\")\n",
    "        mask = torch.tensor(read_img(f\"/playpen-nas-ssd/xiaolong/data/DiLiGenT-MV/mvpmsData/{list_obj[obj_index]}PNG/mask_depth/{gt_view}.png\")[:, :-4])\n",
    "        gt = torch.tensor(gt[:, :-4])\n",
    "        gt = (gt < 0) + gt\n",
    "        gt = torch.tensor(gt)\n",
    "        gt = gt * mask\n",
    "        difference = torch.abs(gt - prediction)\n",
    "        save_directory_img = \"/playpen-nas-ssd/xiaolong/project/MVSNet_pytorch/result_errormap/\" + list_obj[obj_index] + f\"_view{view_index}\" + \".png\"\n",
    "        save_directory_tensor = \"/playpen-nas-ssd/xiaolong/project/MVSNet_pytorch/result_errormap/\" + list_obj[obj_index] + f\"_view{view_index}\" + \".pt\"\n",
    "        toImage(difference, save_directory_img, min_1 = 0, max_1 = 100)\n",
    "        torch.save(difference, save_directory_tensor)\n",
    "        obj_error[obj_index, view_index-1] = torch.sum(difference) / torch.count_nonzero(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = obj_error.cpu().numpy()\n",
    "np.savetxt(\"yeah.csv\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.3947,  3.9124,  5.4983,  6.6486,  6.4028,  5.9202,  3.9855,  4.4135,\n",
       "          4.4926,  4.9370,  4.6464,  3.9140,  3.1896,  4.6744,  6.8803, 10.7236,\n",
       "         11.2102,  7.9253,  6.8133,  6.7411],\n",
       "        [ 3.5168,  3.6152,  4.1245,  4.8840,  5.2177,  6.9052,  8.5578,  5.1742,\n",
       "          3.3325,  3.3357,  3.4309,  3.8497,  5.6784,  7.1061,  7.1715,  5.8814,\n",
       "          5.6710,  5.5074,  6.6406,  6.5281],\n",
       "        [ 9.7015, 12.6548, 16.5676, 16.4373, 15.5530, 29.5888,  8.4015,  6.5955,\n",
       "          6.6257,  7.3598,  7.8918,  9.1364,  9.8102,  8.7715, 11.5891, 23.9889,\n",
       "         23.2645, 13.9336, 12.5872, 16.7200],\n",
       "        [ 3.0618,  3.8760,  5.6505,  8.9872, 11.0102,  9.5670,  8.4240,  6.4321,\n",
       "          6.0971,  5.6828,  5.4337,  5.4033,  7.2765,  7.1474,  6.8274,  9.6885,\n",
       "         10.2918,  6.8654,  5.1656,  5.5246],\n",
       "        [12.7976, 15.6977, 15.0285, 11.5030,  5.7863,  4.4326,  2.9557,  2.0441,\n",
       "          3.2949,  3.4943,  3.2918,  5.1587,  7.7921,  8.0286,  6.1764,  5.4719,\n",
       "          5.9524, 10.1116, 13.5540, 18.8330]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvsnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "001342c73d8b336921a8368b033fea6a6bfd56e5235e37289a1cd819e2617100"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
